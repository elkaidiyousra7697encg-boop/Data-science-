# -*- coding: utf-8 -*-
"""Analyse 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CK3segDcW9pVEo8rkiryp2BCrnguPKy1
"""

#Importing Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#For ignoring warning
import warnings
warnings.filterwarnings("ignore")

df=pd.read_csv('/content/drive/MyDrive/prédiction/Analyse  2/Winter_Fashion_Trends_Dataset.csv')
df

"""# Task
Perform preliminary data analysis (EDA) on the `df` DataFrame, including checking for missing values and understanding variable distributions. Clean the data by handling missing values and encoding categorical variables. Identify 'Price(USD)' as the target variable and relevant features. Provide comments in French on each preparation step.

## Analyse Préliminaire et Nettoyage des Données

### Subtask:
Exécuter une analyse exploratoire des données (EDA) pour comprendre la distribution des variables et vérifier les valeurs manquantes. Effectuer le nettoyage des données, y compris la gestion des valeurs manquantes et l'encodage des variables catégorielles. Identifier la variable cible (par exemple, 'Price(USD)') et les caractéristiques (features) pertinentes. Fournir des commentaires en français sur chaque étape de préparation.

**Reasoning**:
The first instruction is to display the first five rows of the DataFrame to get an initial overview of the data. I will use the `df.head()` method for this purpose.
"""

print("Aperçu des premières lignes pour comprendre la structure des données.")
df.head()

"""**Reasoning**:
The next step is to display concise information about the DataFrame, including data types and non-null values per column, using the `.info()` method.


"""

print("Vérification des types de données et identification des valeurs manquantes potentielles.")
df.info()

"""**Reasoning**:
As instructed, I will calculate and display the number of missing values for each column in the DataFrame to precisely quantify them.


"""

print("Quantification exacte des valeurs manquantes par colonne.")
df.isnull().sum()

"""**Reasoning**:
As per the instructions, I will display the descriptive statistics for all numerical columns in the DataFrame to understand their central tendency, dispersion, and shape.


"""

print("Analyse statistique des variables numériques (moyenne, écart-type, min, max, quartiles).")
df.describe()

"""**Reasoning**:
Following the instructions, I will identify numerical columns and attempt to fill any missing values with their respective medians, as per step 5 of the subtask. Although no missing values were found in previous steps, this code demonstrates the intended data cleaning process.


"""

print("Imputation des valeurs numériques manquantes par la médiane pour éviter la distorsion due aux valeurs extrêmes.")
numerical_cols = df.select_dtypes(include=np.number).columns
for col in numerical_cols:
    if df[col].isnull().any():
        median_val = df[col].median()
        df[col].fillna(median_val, inplace=True)
print("Vérification après imputation des valeurs numériques:")
print(df[numerical_cols].isnull().sum())

"""**Reasoning**:
As per the instructions, I will identify categorical columns and fill any missing values with their respective modes to preserve the most frequent distribution. Although previous steps showed no missing values, this code demonstrates the intended cleaning process for categorical data.


"""

print("Imputation des valeurs catégorielles manquantes par le mode pour préserver la distribution la plus fréquente.")
categorical_cols = df.select_dtypes(include='object').columns
for col in categorical_cols:
    if df[col].isnull().any():
        mode_val = df[col].mode()[0]
        df[col].fillna(mode_val, inplace=True)
print("Vérification après imputation des valeurs catégorielles:")
print(df[categorical_cols].isnull().sum())

"""**Reasoning**:
As instructed, I will create histograms for the relevant numerical variables ('Price(USD)', 'Popularity_Score', 'Customer_Rating') to visualize their distributions, which helps in identifying patterns like normality, skewness, or outliers. This corresponds to step 7 of the subtask.


"""

print("Visualisation de la distribution des variables numériques pour détecter la normalité, l'asymétrie ou les valeurs aberrantes.")

plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
sns.histplot(df['Price(USD)'], kde=True)
plt.title('Distribution du Prix (USD)')
plt.xlabel('Prix (USD)')
plt.ylabel('Fréquence')

plt.subplot(1, 3, 2)
sns.histplot(df['Popularity_Score'], kde=True)
plt.title('Distribution du Score de Popularité')
plt.xlabel('Score de Popularité')
plt.ylabel('Fréquence')

plt.subplot(1, 3, 3)
sns.histplot(df['Customer_Rating'], kde=True)
plt.title('Distribution de la Note Client')
plt.xlabel('Note Client')
plt.ylabel('Fréquence')

plt.tight_layout()
plt.show()

"""**Reasoning**:
As instructed, I will create bar plots for the specified categorical variables ('Brand', 'Category', 'Color', 'Material', 'Style', 'Gender', 'Season', 'Trend_Status') to visualize the frequency of each category, which is essential for understanding their distribution. This corresponds to step 8 of the subtask.


"""

print("Visualisation des fréquences des catégories pour comprendre la répartition des observations.")

categorical_cols_to_plot = ['Brand', 'Category', 'Color', 'Material', 'Style', 'Gender', 'Season', 'Trend_Status']

plt.figure(figsize=(20, 20)) # Adjust figure size for better readability

for i, col in enumerate(categorical_cols_to_plot):
    plt.subplot(4, 2, i + 1) # Create a 4x2 grid for 8 plots
    sns.countplot(data=df, y=col, order=df[col].value_counts().index, palette='viridis')
    plt.title(f'Fréquence de la Catégorie: {col}')
    plt.xlabel('Nombre d\'Occurrences')
    plt.ylabel(col)

plt.tight_layout()
plt.show()

"""**Reasoning**:
As instructed, I will identify categorical columns (excluding 'ID') and apply One-Hot encoding to convert them into numerical binary variables. A new DataFrame will be created to store these encoded data, which is a common practice for preparing categorical features for machine learning models.


"""

print("Conversion des variables catégorielles en format numérique via l'encodage One-Hot, nécessaire pour la plupart des algorithmes d'apprentissage automatique.")

categorical_cols_for_encoding = df.select_dtypes(include=['object', 'category']).columns.tolist()
# Exclude 'ID' if it was mistakenly identified as categorical or if it's not needed for encoding
if 'ID' in categorical_cols_for_encoding:
    categorical_cols_for_encoding.remove('ID')

# Create a copy to avoid modifying the original DataFrame directly before encoding
df_encoded = df.copy()

df_encoded = pd.get_dummies(df_encoded, columns=categorical_cols_for_encoding, drop_first=True)

print("Le DataFrame après encodage One-Hot a été créé.")

"""**Reasoning**:
As instructed, I will display the first five rows of the `df_encoded` DataFrame to visually inspect the result of the One-Hot encoding and verify the transformation, which is step 10 of the subtask.


"""

print("Vérification de l'application correcte de l'encodage One-Hot.")
df_encoded.head()

"""**Reasoning**:
As instructed, I will define the target variable `y` as 'Price(USD)' and the features `X` as all other columns in the `df_encoded` DataFrame, excluding the 'ID' column. This prepares the data for model training.


"""

print("Définition de la variable dépendante ('Price(USD)') et des variables indépendantes (caractéristiques) pour la modélisation.")
y = df_encoded['Price(USD)']
X = df_encoded.drop(['ID', 'Price(USD)'], axis=1)
print("Variables X et y définies.")

"""**Reasoning**:
As instructed, I will display the dimensions (number of rows and columns) of the `X` and `y` DataFrames to confirm their structure and ensure correct preparation for model training.


"""

print("Confirmation des dimensions des ensembles de caractéristiques et de la variable cible.")
print(f"Dimensions de X: {X.shape}")
print(f"Dimensions de y: {y.shape}")

"""## Régression Linéaire Simple et Multiple

### Subtask:
Appliquer un modèle de régression linéaire simple et un modèle de régression linéaire multiple sur les données prétraitées. Entraîner les modèles, évaluer leurs performances (R-squared, MAE, MSE) et visualiser les prédictions par rapport aux valeurs réelles. Inclure des commentaires en français sur les résultats et les graphiques.

**Reasoning**:
The first step is to split the dataset into training and testing sets to prepare for model training and evaluation. I need to import `train_test_split` from `sklearn.model_selection` for this purpose. I'll use an 80/20 split and a `random_state` for reproducibility.
"""

print("Séparation des données en ensembles d'entraînement et de test (80% entraînement, 20% test).")
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Taille de l'ensemble d'entraînement X: {X_train.shape}")
print(f"Taille de l'ensemble de test X: {X_test.shape}")
print(f"Taille de l'ensemble d'entraînement y: {y_train.shape}")
print(f"Taille de l'ensemble de test y: {y_test.shape}")

"""**Reasoning**:
Following the instructions, I will now implement the Simple Linear Regression model. This involves selecting 'Popularity_Score' as the single feature, training the model, making predictions, calculating evaluation metrics (MAE, MSE, R-squared), and visualizing the predictions against actual values.


"""

print("\n--- Régression Linéaire Simple ---")
# 3a. Sélection de la colonne 'Popularity_Score' pour la régression simple
X_train_simple = X_train[['Popularity_Score']]
X_test_simple = X_test[['Popularity_Score']]

# 3b & 3c. Importation et entraînement du modèle de régression linéaire simple
from sklearn.linear_model import LinearRegression
simple_linear_model = LinearRegression()
simple_linear_model.fit(X_train_simple, y_train)

# 3d. Prédictions sur les données de test de la régression simple
y_pred_simple = simple_linear_model.predict(X_test_simple)

# 3e & 3f. Calcul et affichage des métriques d'évaluation pour la régression simple
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

mae_simple = mean_absolute_error(y_test, y_pred_simple)
mse_simple = mean_squared_error(y_test, y_pred_simple)
r2_simple = r2_score(y_test, y_pred_simple)

print(f"MAE (Simple Linear Regression): {mae_simple:.2f}")
print(f"MSE (Simple Linear Regression): {mse_simple:.2f}")
print(f"R-squared (Simple Linear Regression): {r2_simple:.2f}")

# 3g. Création d'un nuage de points des valeurs réelles vs prédites pour la régression simple
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred_simple, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Ligne y=x
plt.title('Prédictions du modèle de Régression Linéaire Simple vs Valeurs Réelles')
plt.xlabel('Prix Réels (USD)')
plt.ylabel('Prix Prédits (USD)')
plt.grid(True)
plt.show()

print("Le modèle de régression linéaire simple a été entraîné et évalué, et ses prédictions visualisées.")

"""**Reasoning**:
As instructed, I will now implement the Multiple Linear Regression model. This involves training the model using all available features in `X_train` and `y_train`, making predictions on `X_test`, calculating evaluation metrics (MAE, MSE, R-squared), and visualizing the predictions against actual values.


"""

print("\n--- Régression Linéaire Multiple ---")
# 4a. Instanciation et entraãnement du modèle de régression linéaire multiple
multiple_linear_model = LinearRegression()
multiple_linear_model.fit(X_train, y_train)

# 4b. Prédictions sur les données de test de la régression multiple
y_pred_multiple = multiple_linear_model.predict(X_test)

# 4c. Calcul et affichage des métriques d'évaluation pour la régression multiple
mae_multiple = mean_absolute_error(y_test, y_pred_multiple)
mse_multiple = mean_squared_error(y_test, y_pred_multiple)
r2_multiple = r2_score(y_test, y_pred_multiple)

print(f"MAE (Multiple Linear Regression): {mae_multiple:.2f}")
print(f"MSE (Multiple Linear Regression): {mse_multiple:.2f}")
print(f"R-squared (Multiple Linear Regression): {r2_multiple:.2f}")

# 4d. Création d'un nuage de points des valeurs réelles vs prédites pour la régression multiple
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred_multiple, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Ligne y=x
plt.title('Prédictions du modèle de Régression Linéaire Multiple vs Valeurs Réelles')
plt.xlabel('Prix Réels (USD)')
plt.ylabel('Prix Prédits (USD)')
plt.grid(True)
plt.show()

print("Le modèle de régression linéaire multiple a été entraãné et évalué, et ses prédictions visualisées.")

"""## Régression Polynomiale

### Subtask:
Mettre en œuvre un modèle de régression polynomiale pour capturer les relations non linéaires. Entraîner le modèle, évaluer ses performances et visualiser les courbes de régression par rapport aux données. Fournir des commentaires en français sur l'ajustement du modèle et les observations.

**Reasoning**:
As instructed, I will implement polynomial regression by transforming the training and testing data into polynomial features, then training a linear regression model on these features, making predictions, and evaluating the model's performance using MAE, MSE, and R-squared. I will use degree 2 for the polynomial features, as specified in the instructions.
"""

print("\n--- Régression Polynomiale ---")
# 1. Importez PolynomialFeatures de sklearn.preprocessing et LinearRegression de sklearn.linear_model.
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# 2. Créez un objet PolynomialFeatures avec un degré approprié (par exemple, degree=2).
# Transformez les données d'entraînement (X_train) et de test (X_test) en caractéristiques polynomiales.
poly_features = PolynomialFeatures(degree=2, include_bias=False) # include_bias=False pour éviter la redondance avec le biais de LinearRegression
X_train_poly = poly_features.fit_transform(X_train)
X_test_poly = poly_features.transform(X_test)

print(f"Dimensions de X_train_poly: {X_train_poly.shape}")
print(f"Dimensions de X_test_poly: {X_test_poly.shape}")

# 3. Instanciez et entraînez un modèle LinearRegression sur les caractéristiques polynomiales transformées.
polynomial_model = LinearRegression()
polynomial_model.fit(X_train_poly, y_train)

# 4. Effectuez des prédictions sur les caractéristiques polynomiales de test.
y_pred_poly = polynomial_model.predict(X_test_poly)

# 5. Calculez et affichez le MAE, le MSE et le R-squared pour le modèle de régression polynomiale.
mae_poly = mean_absolute_error(y_test, y_pred_poly)
mse_poly = mean_squared_error(y_test, y_pred_poly)
r2_poly = r2_score(y_test, y_pred_poly)

print(f"MAE (Régression Polynomiale): {mae_poly:.2f}")
print(f"MSE (Régression Polynomiale): {mse_poly:.2f}")
print(f"R-squared (Régression Polynomiale): {r2_poly:.2f}")

"""**Reasoning**:
As instructed, I will create a scatter plot to visualize the actual prices against the predicted prices from the polynomial regression model. I will add a diagonal line for comparison and include French titles and labels, then display the plot. This corresponds to step 6 of the subtask.


"""

print("\n--- Régression Polynomiale ---")
# 1. Importez PolynomialFeatures de sklearn.preprocessing et LinearRegression de sklearn.linear_model.
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# 2. Créez un objet PolynomialFeatures avec un degré approprié (par exemple, degree=2).
# Transformez les données d'entraènement (X_train) et de test (X_test) en caractéristiques polynomiales.
poly_features = PolynomialFeatures(degree=2, include_bias=False) # include_bias=False pour éviter la redondance avec le biais de LinearRegression
X_train_poly = poly_features.fit_transform(X_train)
X_test_poly = poly_features.transform(X_test)

print(f"Dimensions de X_train_poly: {X_train_poly.shape}")
print(f"Dimensions de X_test_poly: {X_test_poly.shape}")

# 3. Instanciez et entraînez un modèle LinearRegression sur les caractéristiques polynomiales transformées.
polynomial_model = LinearRegression()
polynomial_model.fit(X_train_poly, y_train)

# 4. Effectuez des prédictions sur les caractéristiques polynomiales de test.
y_pred_poly = polynomial_model.predict(X_test_poly)

# 5. Calculez et affichez le MAE, le MSE et le R-squared pour le modèle de régression polynomiale.
mae_poly = mean_absolute_error(y_test, y_pred_poly)
mse_poly = mean_squared_error(y_test, y_pred_poly)
r2_poly = r2_score(y_test, y_pred_poly)

print(f"MAE (Régression Polynomiale): {mae_poly:.2f}")
print(f"MSE (Régression Polynomiale): {mse_poly:.2f}")
print(f"R-squared (Régression Polynomiale): {r2_poly:.2f}")

# 6. Créez un nuage de points pour visualiser les prix réels (y_test) par rapport aux prix prédits (y_pred_poly).
# Ajoutez une ligne diagonale (y=x) pour faciliter la comparaison. Ajoutez un titre et des étiquettes d'axes en français.
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred_poly, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Ligne y=x
plt.title('Prédictions du modèle de Régression Polynomiale vs Valeurs Réelles')
plt.xlabel('Prix Réels (USD)')
plt.ylabel('Prix Prédits (USD)')
plt.grid(True)
plt.show()

print("Le modèle de régression polynomiale a été entraîné, évalué et ses prédictions visualisées.")

"""## Régression avec Régularisation (Ridge et Lasso)

### Subtask:
Appliquer les modèles de régression Ridge et Lasso pour la régularisation et la sélection de caractéristiques. Entraîner ces modèles, comparer leurs coefficients et leurs performances avec la régression linéaire standard. Visualiser l'impact de la régularisation et commenter les résultats en français.

**Reasoning**:
As instructed, I will import the necessary `Ridge` model from `sklearn.linear_model` and evaluation metrics from `sklearn.metrics`. Then, I will instantiate, train, and evaluate the Ridge regression model, making predictions and calculating MAE, MSE, and R-squared.
"""

print("\n--- Régression Ridge ---")
# 1. Importez les classes Ridge et Lasso de sklearn.linear_model.
# 2. Instanciez un modèle Ridge avec un paramètre alpha approprié (par exemple, alpha=1.0) et entraînez-le sur X_train et y_train.
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

ridge_model = Ridge(alpha=1.0) # On peut ajuster alpha selon les besoins
ridge_model.fit(X_train, y_train)

# 3. Effectuez des prédictions sur X_test avec le modèle Ridge.
y_pred_ridge = ridge_model.predict(X_test)

# 4. Calculez et affichez le MAE, le MSE et le R-squared pour le modèle Ridge.
mae_ridge = mean_absolute_error(y_test, y_pred_ridge)
mse_ridge = mean_squared_error(y_test, y_pred_ridge)
r2_ridge = r2_score(y_test, y_pred_ridge)

print(f"MAE (Régression Ridge): {mae_ridge:.2f}")
print(f"MSE (Régression Ridge): {mse_ridge:.2f}")
print(f"R-squared (Régression Ridge): {r2_ridge:.2f}")

print("Le modèle Ridge a été entraîné et évalué.")

"""**Reasoning**:
Following the instructions, I will now implement the Lasso regression model by instantiating it with an appropriate alpha, training it on the training data, making predictions on the test data, and then calculating and displaying the MAE, MSE, and R-squared metrics.


"""

print("\n--- Régression Lasso ---")
from sklearn.linear_model import Lasso

# 5. Instanciez un modèle Lasso avec un paramètre alpha approprié (par exemple, alpha=1.0) et entraînez-le sur X_train et y_train.
lasso_model = Lasso(alpha=1.0, max_iter=10000) # Augmenter max_iter si nécessaire pour la convergence
lasso_model.fit(X_train, y_train)

# 6. Effectuez des prédictions sur X_test avec le modèle Lasso.
y_pred_lasso = lasso_model.predict(X_test)

# 7. Calculez et affichez le MAE, le MSE et le R-squared pour le modèle Lasso.
mae_lasso = mean_absolute_error(y_test, y_pred_lasso)
mse_lasso = mean_squared_error(y_test, y_pred_lasso)
r2_lasso = r2_score(y_test, y_pred_lasso)

print(f"MAE (Régression Lasso): {mae_lasso:.2f}")
print(f"MSE (Régression Lasso): {mse_lasso:.2f}")
print(f"R-squared (Régression Lasso): {r2_lasso:.2f}")

print("Le modèle Lasso a été entraâné et évalué.")

"""**Reasoning**:
As instructed, I will create a scatter plot to visualize the actual prices (`y_test`) against the predicted prices (`y_pred_ridge`) from the Ridge regression model. I will add a diagonal line for comparison and include French titles and labels, then display the plot.


"""

print("Visualisation des prédictions du modèle Ridge par rapport aux valeurs réelles.")

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred_ridge, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Ligne y=x
plt.title('Prédictions du modèle Ridge vs Valeurs Réelles')
plt.xlabel('Prix Réels (USD)')
plt.ylabel('Prix Prédits (USD)')
plt.grid(True)
plt.show()

print("Le nuage de points pour le modèle Ridge a été généré.")

"""**Reasoning**:
As instructed, I will create a scatter plot to visualize the actual prices (`y_test`) against the predicted prices (`y_pred_lasso`) from the Lasso regression model. I will add a diagonal line for comparison and include French titles and labels, then display the plot.


"""

print("Visualisation des prédictions du modèle Lasso par rapport aux valeurs réelles.")

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred_lasso, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Ligne y=x
plt.title('Prédictions du modèle Lasso vs Valeurs Réelles')
plt.xlabel('Prix Réels (USD)')
plt.ylabel('Prix Prédits (USD)')
plt.grid(True)
plt.show()

print("Le nuage de points pour le modèle Lasso a été généré.")

"""**Reasoning**:
As instructed, I will display the coefficients of the Ridge and Lasso models to understand their magnitude and identify which features might be suppressed or have reduced impact, then provide a commentary in French. This completes step 10 of the subtask.


"""

print("\n--- Analyse des Coefficients de Régularisation ---")

# Coefficients du modèle Ridge
print("Coefficients du modèle Ridge:\n")
ridge_coef_df = pd.DataFrame({'Feature': X.columns, 'Coefficient': ridge_model.coef_})
ridge_coef_df['Absolute_Coefficient'] = np.abs(ridge_coef_df['Coefficient'])
ridge_coef_df = ridge_coef_df.sort_values(by='Absolute_Coefficient', ascending=False)
print(ridge_coef_df.head(10)) # Afficher les 10 coefficients les plus importants

print("\nCoefficients du modèle Lasso:\n")
# Coefficients du modèle Lasso
lasso_coef_df = pd.DataFrame({'Feature': X.columns, 'Coefficient': lasso_model.coef_})
lasso_coef_df['Absolute_Coefficient'] = np.abs(lasso_coef_df['Coefficient'])
lasso_coef_df = lasso_coef_df.sort_values(by='Absolute_Coefficient', ascending=False)
print(lasso_coef_df.head(10)) # Afficher les 10 coefficients les plus importants

print("\nComparaison des coefficients:\n")
print("Le modèle Ridge tend à réduire les coefficients des caractéristiques sans les annuler complètement, ce qui maintient toutes les caractéristiques dans le modèle mais réduit leur influence. Le modèle Lasso, en revanche, peut réduire certains coefficients à zéro, effectuant ainsi une sélection de caractéristiques en éliminant les moins importantes. Cela peut être observé en comparant les valeurs des coefficients: Lasso aura plus de zéros ou de valeurs très proches de zéro pour les caractéristiques jugées non pertinentes.")

"""## Modèles de Régression Basés sur les Arbres (Arbre de Décision, Forêt Aléatoire)

### Subtask:
Implémenter et entraîner un modèle d'arbre de décision pour la régression, évaluer sa performance et visualiser les prédictions.

**Reasoning**:
As instructed, I will implement a Decision Tree Regressor model by importing the necessary class, instantiating and training it on the training data, making predictions, calculating evaluation metrics (MAE, MSE, R-squared), and then providing a commentary on the results.
"""

print("\n--- Modèle d'Arbre de Décision pour la Régression ---")

# 1. Importez la classe DecisionTreeRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# 2. Instanciez et entraînez le modèle d'arbre de décision
dt_model = DecisionTreeRegressor(random_state=42)
dt_model.fit(X_train, y_train)

# 3. Effectuez des prédictions sur X_test
y_pred_dt = dt_model.predict(X_test)

# 5. Calculez et affichez le MAE, le MSE et le R-squared
mae_dt = mean_absolute_error(y_test, y_pred_dt)
mse_dt = mean_squared_error(y_test, y_pred_dt)
r2_dt = r2_score(y_test, y_pred_dt)

print(f"MAE (Arbre de Décision): {mae_dt:.2f}")
print(f"MSE (Arbre de Décision): {mse_dt:.2f}")
print(f"R-squared (Arbre de Décision): {r2_dt:.2f}")

print("Commentaire sur les résultats: Le modèle d'arbre de décision a été entraîné. Les métriques MAE, MSE et R-squared indiquent la performance du modèle sur l'ensemble de test. Un R-squared positif mais faible suggère que le modèle capture une certaine variance mais qu'il y a encore beaucoup de variabilité inexpliquée, ou qu'il pourrait y avoir un surapprentissage si le modèle est trop complexe.")

"""**Reasoning**:
As instructed, I will create a scatter plot to visualize the actual prices (`y_test`) against the predicted prices (`y_pred_dt`) from the Decision Tree Regressor model. I will add a diagonal line for comparison and include French titles and labels, then display the plot.


"""

print("Visualisation des prédictions du modèle d'Arbre de Décision par rapport aux valeurs réelles.")

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred_dt, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Ligne y=x
plt.title("Prédictions du modèle d'Arbre de Décision vs Valeurs Réelles")
plt.xlabel('Prix Réels (USD)')
plt.ylabel('Prix Prédits (USD)')
plt.grid(True)
plt.show()

print("Le nuage de points pour le modèle d'Arbre de Décision a été généré.")

"""## Modèles de Régression Basés sur les Arbres (Arbre de Décision, Forêt Aléatoire)

### Subtask:
Implémenter et entraîner un modèle de forêt aléatoire pour la régression, évaluer sa performance et visualiser les prédictions.

**Reasoning**:
As instructed, I will implement a Random Forest Regressor model, train it, make predictions, evaluate its performance using MAE, MSE, and R-squared, and then visualize the predictions against the actual values. I will also provide a commentary on the results.
"""

print("\n--- Modèle de Forêt Aléatoire pour la Régression ---")

# 1. Importez la classe RandomForestRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# 2. Instanciez un modèle RandomForestRegressor et entraînez-le
rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X_train, y_train)

# 3. Effectuez des prédictions sur X_test
y_pred_rf = rf_model.predict(X_test)

# 4. Calculez et affichez le MAE, le MSE et le R-squared
mae_rf = mean_absolute_error(y_test, y_pred_rf)
mse_rf = mean_squared_error(y_test, y_pred_rf)
r2_rf = r2_score(y_test, y_pred_rf)

print(f"MAE (Forêt Aléatoire): {mae_rf:.2f}")
print(f"MSE (Forêt Aléatoire): {mse_rf:.2f}")
print(f"R-squared (Forêt Aléatoire): {r2_rf:.2f}")

# 5. Commentaire sur les résultats
print("Commentaire sur les résultats: Le modèle de Forêt Aléatoire a été entraîné. En général, les Forêts Aléatoires tendent à être plus robustes et à mieux gérer les relations non linéaires et l'interaction entre les caractéristiques que les modèles linéaires simples ou même la régression polynomiale. Les métriques obtenues indiquent si ce modèle surpasse ou non les précédents, un R-squared plus élevé et des MAE/MSE plus faibles sont souhaitables.")

# 6. Créez un nuage de points pour visualiser les prix réels (y_test) par rapport aux prix prédits (y_pred_rf).
# Ajoutez une ligne diagonale (y=x) pour faciliter la comparaison. Ajoutez un titre et des étiquettes d'axes en français.
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred_rf, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Ligne y=x
plt.title("Prédictions du modèle de Forêt Aléatoire vs Valeurs Réelles")
plt.xlabel('Prix Réels (USD)')
plt.ylabel('Prix Prédits (USD)')
plt.grid(True)
plt.show()

print("Le modèle de forêt aléatoire a été entraîné, évalué et ses prédictions visualisées.")

"""## Machine à Vecteurs de Support pour la Régression (SVR)

### Subtask:
Appliquer un modèle de Support Vector Regressor (SVR). Entraîner le modèle, évaluer ses performances et visualiser les prédictions. Discuter des avantages et des inconvénients du SVR par rapport aux autres modèles, avec des commentaires en français.

**Reasoning**:
The first step is to implement the SVR model by importing necessary libraries, instantiating and training the model on the training data, making predictions on the test data, and calculating its evaluation metrics (MAE, MSE, R-squared) as per instructions 1-4.
"""

print("\n--- Machine à Vecteurs de Support pour la Régression (SVR) ---")

# 1. Importez la classe SVR et les métriques d'évaluation
from sklearn.svm import SVR
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# 2. Instanciez un modèle SVR avec des paramètres par défaut et entraînez-le
# Pour SVR, il est souvent recommandé de scaler les données. Pour l'instant, nous utilisons les données brutes.
# Le paramètre 'kernel' peut être ajusté (e.g., 'linear', 'poly', 'rbf'). 'rbf' est le défaut.
# C et epsilon sont d'autres hyperparamètres importants.
svr_model = SVR(kernel='rbf', C=100, epsilon=0.1) # C et epsilon sont des valeurs initiales, peuvent être ajustées
svr_model.fit(X_train, y_train)

# 3. Effectuez des prédictions sur X_test
y_pred_svr = svr_model.predict(X_test)

# 4. Calculez et affichez le MAE, le MSE et le R-squared
mae_svr = mean_absolute_error(y_test, y_pred_svr)
mse_svr = mean_squared_error(y_test, y_pred_svr)
r2_svr = r2_score(y_test, y_pred_svr)

print(f"MAE (SVR): {mae_svr:.2f}")
print(f"MSE (SVR): {mse_svr:.2f}")
print(f"R-squared (SVR): {r2_svr:.2f}")

print("Le modèle SVR a été entraîné et ses performances évaluées.")

"""**Reasoning**:
As instructed, I will create a scatter plot to visualize the actual prices (`y_test`) against the predicted prices (`y_pred_svr`) from the SVR model. I will add a diagonal line for comparison and include French titles and labels, then display the plot.


"""

print("Visualisation des prédictions du modèle SVR par rapport aux valeurs réelles.")

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred_svr, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Ligne y=x
plt.title('Prédictions du modèle SVR vs Valeurs Réelles')
plt.xlabel('Prix Réels (USD)')
plt.ylabel('Prix Prédits (USD)')
plt.grid(True)
plt.show()

"""### Commentaire sur les performances du modèle SVR

Le modèle SVR (Support Vector Regressor) a été entraîné et évalué. Ses métriques (MAE, MSE, R-squared) fournissent une indication de sa performance par rapport aux modèles de régression linéaire simple et multiple, polynomiale, d'arbre de décision et de forêt aléatoire.

**Avantages du SVR :**
*   **Robustesse aux valeurs aberrantes :** Contrairement aux modèles de régression linéaire qui minimisent l'erreur quadratique, SVR ignore les points qui se trouvent dans la marge d'erreur (epsilon), ce qui le rend moins sensible aux valeurs aberrantes.
*   **Gestion des relations non linéaires :** Grâce à l'utilisation de noyaux (comme le noyau RBF utilisé ici), le SVR peut modéliser des relations non linéaires complexes entre les caractéristiques et la variable cible, sans nécessiter une transformation explicite des caractéristiques (comme la régression polynomiale).
*   **Moins sujet au surapprentissage que les arbres :** Comparé aux arbres de décision et parfois aux forêts aléatoires (sans réglage fin des hyperparamètres), le SVR peut être moins sujet au surapprentissage, surtout avec une bonne sélection des hyperparamètres `C` (pénalité d'erreur) et `epsilon` (marge d'erreur).

**Inconvénients du SVR :**
*   **Sensibilité à l'échelle des données :** Le SVR est très sensible à l'échelle des caractéristiques. Idéalement, les données d'entrée devraient être mises à l'échelle (normalisées ou standardisées) pour que le modèle fonctionne de manière optimale. Dans notre cas, les données n'ont pas été scalées, ce qui pourrait impacter la performance.
*   **Complexité des hyperparamètres :** Le choix des hyperparamètres `C`, `epsilon` et du type de `kernel` peut être délicat et demande souvent une optimisation via des techniques comme la validation croisée et la recherche par grille/aléatoire.
*   **Coût computationnel :** Pour de grands ensembles de données, l'entraînement d'un SVR peut être coûteux en termes de temps de calcul, en particulier avec certains noyaux.
*   **Interprétabilité :** Comme pour la plupart des modèles basés sur des noyaux, le SVR est un modèle de type 'boîte noire', ce qui rend l'interprétation des relations entre les caractéristiques et la prédiction plus difficile que pour les modèles linéaires ou les arbres de décision.

En comparant les métriques obtenues, on peut évaluer si le SVR a apporté une amélioration significative. Si les métriques ne sont pas meilleures, cela pourrait être dû à l'absence de scalage des données ou à un besoin d'optimisation des hyperparamètres.

## Comparaison et Synthèse des Modèles

### Subtask:
Comparer les performances de tous les modèles de régression implémentés à l'aide de métriques clés (par exemple, MAE, MSE, R-squared) et de visualisations globales (par exemple, des graphiques des erreurs résiduelles ou des prédictions vs. réelles pour chaque modèle). Résumer les forces et les faiblesses de chaque type de régression et fournir des commentaires en français pour conclure l'analyse.

**Reasoning**:
To compare the models comprehensively, I will first compile all the evaluation metrics (MAE, MSE, R-squared) into a single pandas DataFrame for easy overview and comparison, as instructed.
"""

print("Création d'un tableau comparatif des métriques de performance pour tous les modèles.")

results = {
    'Model': ['Simple Linear Regression', 'Multiple Linear Regression', 'Polynomial Regression', 'Ridge Regression', 'Lasso Regression', 'Decision Tree', 'Random Forest', 'SVR'],
    'MAE': [mae_simple, mae_multiple, mae_poly, mae_ridge, mae_lasso, mae_dt, mae_rf, mae_svr],
    'MSE': [mse_simple, mse_multiple, mse_poly, mse_ridge, mse_lasso, mse_dt, mse_rf, mse_svr],
    'R-squared': [r2_simple, r2_multiple, r2_poly, r2_ridge, r2_lasso, r2_dt, r2_rf, r2_svr]
}

results_df = pd.DataFrame(results)
results_df = results_df.round(2) # Arrondir pour une meilleure lisibilité

print("Tableau Comparatif des Performances des Modèles:")
print(results_df)

"""**Reasoning**:
As instructed, I will generate bar charts to visually compare the MAE, MSE, and R-squared metrics for all trained models. This will provide a clear graphical representation of their performance differences.


"""

print("Génération de graphiques à barres pour comparer visuellement les performances des modèles.")

# Création des graphiques à barres pour MAE, MSE et R-squared
plt.figure(figsize=(18, 6))

# Graphique pour MAE
plt.subplot(1, 3, 1)
sns.barplot(x='Model', y='MAE', data=results_df, palette='viridis')
plt.title('Comparaison du MAE des Modèles')
plt.xlabel('Modèle')
plt.ylabel('Erreur Absolue Moyenne (MAE)')
plt.xticks(rotation=45, ha='right')

# Graphique pour MSE
plt.subplot(1, 3, 2)
sns.barplot(x='Model', y='MSE', data=results_df, palette='magma')
plt.title('Comparaison du MSE des Modèles')
plt.xlabel('Modèle')
plt.ylabel('Erreur Quadratique Moyenne (MSE)')
plt.xticks(rotation=45, ha='right')

# Graphique pour R-squared
plt.subplot(1, 3, 3)
sns.barplot(x='Model', y='R-squared', data=results_df, palette='plasma')
plt.title('Comparaison du R-squared des Modèles')
plt.xlabel('Modèle')
plt.ylabel('R-squared')
plt.xticks(rotation=45, ha='right')

plt.tight_layout()
plt.show()

print("Les graphiques comparatifs des métriques de performance ont été générés.")

"""### Synthèse des Performances des Modèles

Après avoir entraîné et évalué plusieurs modèles de régression pour prédire le prix des articles, nous pouvons tirer les conclusions suivantes:

*   **Régression Linéaire Simple (Popularity_Score)**: Ce modèle a montré des performances médiocres avec un R-squared négatif (-0.26), indiquant qu'il est moins performant qu'un simple modèle prédisant la moyenne. Cela suggère que la 'Popularity_Score' seule n'est pas un bon prédicteur du prix.

*   **Régression Linéaire Multiple**: Bien que prenant en compte toutes les caractéristiques, ce modèle a également un R-squared négatif (-0.44), et même pire que la régression simple. Cela peut indiquer que les relations entre les caractéristiques et le prix ne sont pas purement linéaires, ou que le modèle est surajusté en raison du grand nombre de caractéristiques encodées par rapport au nombre d'échantillons.

*   **Régression Polynomiale (degré 2)**: Ce modèle présente les pires performances avec un R-squared de -1.09. L'ajout de termes polynomiaux a probablement conduit à un surajustement significatif, où le modèle a tenté de capturer le bruit dans les données d'entraînement plutôt que les relations sous-jacentes, ce qui est exacerbé par le grand nombre de caractéristiques après la transformation polynomiale.

*   **Régression Ridge et Lasso**: Ces modèles de régularisation ont été introduits pour pallier le surajustement potentiel de la régression linéaire multiple. Ridge (-0.41) et Lasso (-0.38) ont des R-squared toujours négatifs, mais légèrement moins mauvais que la régression linéaire multiple et la régression polynomiale. Lasso, en particulier, a la capacité d'effectuer une sélection de caractéristiques en mettant à zéro les coefficients des caractéristiques moins importantes, ce qui est visible dans l'analyse des coefficients.

*   **Arbre de Décision**: Ce modèle, de nature non linéaire, a également obtenu un R-squared négatif (-0.85). Cela suggère qu'un seul arbre de décision n'est pas suffisant pour capturer les complexités du dataset, ou qu'il est également surajusté sans une optimisation appropriée des hyperparamètres (profondeur maximale, nombre minimum d'échantillons par feuille, etc.).

*   **Forêt Aléatoire**: Ce modèle d'ensemble, construit à partir de multiples arbres de décision, montre les meilleures performances parmi tous les modèles testés avec un MAE de 177.39 et un R-squared de -0.17. Bien que le R-squared reste négatif, il est le plus proche de zéro, ce qui indique que ce modèle explique mieux la variance que les autres. Les forêts aléatoires sont robustes au surajustement et peuvent capturer des relations non linéaires complexes, mais des hyperparamètres par défaut ne sont pas toujours optimaux.

*   **Machine à Vecteurs de Support pour la Régression (SVR)**: Le SVR a des performances similaires aux modèles linéaires régularisés, avec un R-squared de -0.29. Comme mentionné précédemment, la performance du SVR peut être fortement influencée par la nécessité de la mise à l'échelle des données et par l'optimisation des hyperparamètres (C, epsilon, kernel), ce qui n'a pas été fait en détail ici.

**Conclusion**: Globalement, aucun des modèles n'a réussi à obtenir un R-squared positif significatif, ce qui indique que nos modèles n'expliquent pas bien la variance du prix et ne sont pas adaptés pour prédire le prix avec précision sur cet ensemble de données. Le **Random Forest** est le modèle le plus performant bien que son R-squared soit négatif, ce qui met en évidence la difficulté de la tâche ou la nécessité d'une exploration plus approfondie des caractéristiques, d'une ingénierie de caractéristiques plus avancée et d'une optimisation des hyperparamètres pour tous les modèles. Il est possible que le jeu de données soit trop petit ou que les caractéristiques disponibles ne soient pas suffisamment corrélées au prix pour permettre une prédiction robuste.

## Final Task

### Subtask:
Fournir une synthèse complète de l'analyse prédictive, en incluant les principaux résultats, les comparaisons entre les modèles et des conclusions en français sur les types de régression les plus adaptés pour ce jeu de données.

## Summary:

### Q&A

**Quels types de régression sont les plus adaptés pour ce jeu de données ?**

D'après l'analyse, aucun des modèles de régression testés n'a montré une performance satisfaisante, tous ayant des valeurs de R-squared négatives. Cependant, parmi les modèles évalués, la **Forêt Aléatoire** a obtenu la performance la moins médiocre (R-squared de -0.17), la plaçant comme le modèle *relativement* le plus adapté. Cela indique une capacité légèrement supérieure à capturer la variance par rapport aux autres modèles, même si elle n'est pas encore prédictive.

### Data Analysis Key Findings

*   **Préparation des Données :** L'ensemble de données initial contenait 150 entrées et 12 colonnes. Aucune valeur manquante n'a été détectée, rendant les étapes d'imputation superflues. Après l'encodage One-Hot des variables catégorielles, l'ensemble de caractéristiques (`X`) a été étendu à 46 dimensions pour 150 échantillons.
*   **Performance Globale des Modèles :** Tous les modèles de régression testés ont affiché des scores R-squared négatifs sur l'ensemble de test, allant de -0.17 à -1.09. Un R-squared négatif signifie que le modèle est moins performant que la simple prédiction de la moyenne de la variable cible.
*   **Régression Linéaire :**
    *   La Régression Linéaire Simple (avec 'Popularity\_Score') a obtenu un R-squared de -0.26, indiquant une faible capacité prédictive.
    *   La Régression Linéaire Multiple a eu une performance encore plus faible avec un R-squared de -0.44.
*   **Régression Polynomiale :** Le modèle de Régression Polynomiale de degré 2 a affiché la pire performance avec un R-squared de -1.09, suggérant un surajustement significatif ou une inadéquation fondamentale pour les relations dans les données.
*   **Régularisation (Ridge et Lasso) :** Les modèles Ridge (R-squared de -0.41) et Lasso (R-squared de -0.38) ont montré des performances légèrement meilleures que la régression linéaire multiple et la régression polynomiale, mais sont restés largement inefficaces.
*   **Modèles Basés sur les Arbres :**
    *   L'Arbre de Décision a eu un R-squared de -0.85, indiquant une très mauvaise prédiction.
    *   La Forêt Aléatoire s'est avérée être le modèle le "moins mauvais" avec le R-squared le plus proche de zéro (-0.17), et a présenté le MAE (177.39) et le MSE (44584.47) les plus bas parmi tous les modèles.
*   **Machine à Vecteurs de Support (SVR) :** Le SVR (avec noyau RBF) a obtenu un R-squared de -0.29, une performance également insatisfaisante, potentiellement due à l'absence de mise à l'échelle des données et d'optimisation des hyperparamètres.

### Insights or Next Steps

*   **Approfondir l'Exploration des Données et l'Ingénierie des Caractéristiques :** Étant donné les performances très faibles de tous les modèles, il est crucial de réévaluer la qualité et la pertinence des caractéristiques existantes. Une analyse plus poussée des corrélations, des interactions entre variables, et l'ingénierie de nouvelles caractéristiques potentiellement plus prédictives sont nécessaires. Il est possible que le jeu de données actuel soit trop limité (seulement 150 échantillons) pour permettre aux modèles de généraliser efficacement.
*   **Optimisation des Hyperparamètres et Validation Croisée :** Pour les modèles non linéaires comme la Forêt Aléatoire et le SVR, les performances peuvent être considérablement améliorées par une optimisation rigoureuse des hyperparamètres via des techniques comme la recherche par grille (Grid Search) ou la recherche aléatoire (Random Search) combinée à la validation croisée. De plus, la mise à l'échelle des caractéristiques (`StandardScaler` ou `MinMaxScaler`) est fortement recommandée pour les modèles sensibles à l'échelle des données comme le SVR.
"""